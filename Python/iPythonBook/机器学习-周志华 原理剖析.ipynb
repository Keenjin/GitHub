{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 绪论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 引言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）生活中，大部分事情，都是基于经验做出的预判。通过对经验的利用，就能对新情况做出有效的决策\n",
    "（2）机器学习主要内容：经验 ——> 数据（由经验数值化） ——> 模型（由数据和学习算法习得的结果） ——> 预判（输入经过模型得到的输出）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 基本术语"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集（data set）：指已知的一堆记录，描述了一堆现象和结果数据组。通常也会将数据集拆分成训练集和测试集\n",
    "示例（instance）/样本（sample）：数据集中一条记录（有可能有x到y的映射，也可能没有，可能y甚至都没有定义）\n",
    "属性（attribute）/特征（feature）：反应记录对象的性质（x_label）\n",
    "属性值（attribute value）：属性上的取值（x，假设有d个属性，在下面，会用x1、x2...xd等来表征每一个属性下的属性值）\n",
    "属性空间（attribute space）/样本空间（sample space）/输入空间：属性张成的空间，\n",
    "特征向量（feature vector）：属性空间中每一个点对应一个向量（这些点由数据集组成），这个就是特征向量X={x1,x2,...,xd}。数据集D={X1,X2,...,Xm}表示m个特征向量（也是m个示例）组成的空间\n",
    "维数（dimensionality）：属性的种类个数\n",
    "样本空间规模：属性可能的取值，即x1或者x2等所有可能的取值（x11、x12、...x1m1）一共m1种可能，x2有m2种可能，那么整个样本空间规模就是m1*m2*...*md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学习（learning）/训练（training）：通过执行某个学习算法（或多个学习算法），从数据中学得模型的过程\n",
    "训练数据（training data）：训练过程使用的数据，通常是数据集的子集\n",
    "训练样本（training sample）：一条训练数据\n",
    "训练集（training set）：训练数据集合\n",
    "假设（hypothesis）：学得模型对应了关于数据的某种潜在规律，称为假设\n",
    "真相/真实（ground-truth）：这种潜在规律自身，称为真相。学习过程就是为了找出或逼近真相\n",
    "模型/学习器（learner）：学习算法在给定数据和参数下的实例化。这里是固化了参数得到的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测（prediction）：判断一条新纪录（不在数据集中）的结果\n",
    "标记（label）：预测模型结果信息（y）\n",
    "样例（example）：拥有了标记信息的示例（已知x：y映射，不一定是一对一的映射，也可能是多对一的映射，y甚至可能只有一种结果）\n",
    "标记空间（label space）/输出空间：所有可能的标记的集合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分类（classification）：标记是离散的取值（y是离散的取值），算法通常是主动设定分类数\n",
    "回归（regression）：标记是连续的取值（y是连续的取值）\n",
    "二分类（binary classification）：只涉及两个类（0/1，-1/+1，是/不是）\n",
    "正类（positive class）：二分类中的一种标记取值\n",
    "反类（negtive class）：二分类中的另一种标记取值\n",
    "多分类（multi-class classification）：涉及多个类别（音乐喜好类别、文章分类等）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试（testing）：对学习算法固化参数后习得的模型，使用其进行预测的过程，称为测试\n",
    "预测样本（testing sample）：被测试的样本（通常从数据集中取一部分出来作为预测样本集）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "聚类（clustering）：通过学习算法，由训练集自动形成分组的过程，称为聚类\n",
    "簇（cluster）：每一个分组，称为簇"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "监督学习（supervised learning）：训练数据拥有标记信息（分类和回归）\n",
    "无监督学习（unsupervised learning）：训练数据没有标记信息（聚类）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "泛化能力（generalization）：学得模型适用于新样本的能力\n",
    "分布（distribution）D：样本空间中全体样本服从的某一个未知分布D。一般训练样本越多，这个分布的信息越多，越可能学得具有强泛化能力的模型\n",
    "独立同分布（independent and identically distributed，简称i.i.d）：样本在未知分布上采样而来的，所以是独立同分布的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 假设空间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）训练样本集合（X_data）到某一个标记（y）的所有可能的集合，组成了假设空间。（注意是某一个标记，而不是多个标记）\n",
    "（2）学习过程可以看做是在假设空间中搜索与训练集匹配（fit）的假设\n",
    "（3）假设空间的规模大小：样本空间规模是m1*m2*...*md，则假设空间的规模大小是(m1+1)*(m2+1)*...*(md+1)+1。取值原因：一共d个属性，每个属性各自的种类数为mi，但是还得包括一种情况，就是输出跟对应的属性xi无关，所以实际一共有mi+1种可能取值。另外，也有可能最终标记y也可能不存在，所以需要再+1\n",
    "（4）版本空间（version space）：假设空间搜索过程中，可能发现有多个假设跟训练集一致，所有这些符合的假设集合，组成版本空间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 归纳偏好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）版本空间可能有多个假设与训练集一致，但是学习模型希望只有一种假设作为判据，这个时候就需要利用归纳偏好\n",
    "（2）奥卡姆剃刀（Occam's razor）：若有多个假设与观察一致，则选最简单的那个\n",
    "（3）回归就是典型的归纳偏好问题，穿过样本点的线，可以有很多条，可以是最小二乘法线性回归模型得到的直线，也可以是SVR得到的曲线，如何选择，即是归纳偏好问题。若两种假设均能有效表示预测，按照奥卡姆剃刀原则，选取线性回归模型，当然，也不一定必然，可能线性回归的泛化能力强，也有可能SVR预测更准确\n",
    "（4）没有免费的午餐定理（No Free Lunch Theorem，简称NFL）：考虑目标函数f服从均匀分布，则任意学习算法总误差相等。定理表明：脱离具体问题，什么学习算法更好的说法将毫无意义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 发展历程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1950~1970，推理期：逻辑理论家程序、通用问题求解程序\n",
    "1970中期，知识期：专家系统，主要是人总结知识，教给计算机\n",
    "1950初期：跳棋程序\n",
    "1950后期：基于神经网络的“连接主义”学习，代表作有感知机、Adaline\n",
    "1960~1970：基于逻辑表示的“符号主义”学习，代表有“结构性学习系统”、“基于逻辑的归纳学习系统”、“概念学习系统”；\n",
    "        决策理论为基础的学习技术和强化学习技术的发展，代表有“学习机器”\n",
    "1980：第一届机器学习研讨会（IWML）\n",
    "1983：出版社《机器学习：一种人工智能途径》\n",
    "1986：第一本机器学习专业期刊Machine Learning创刊\n",
    "1989：人工智能领域权威期刊Artificial Intelligence出版机器学习专辑\n",
    "1990：MIT出版社《机器学习：范型与方法》书籍\n",
    "1983：《人工智能手册》把机器学习划分为：“机械学习”（死记硬背的学习）、“示教学习”（从指令中学习）、“类比学习”（通过观察和发现学习）、“归纳学习”（从样例中学习）\n",
    "1980~1990：归纳学习的一大主流是“符号主义”学习，代表包括决策树和基于逻辑的学习，典型的决策树学习以信息论为基础，以信息熵的最小化为目标，直接模拟人类对概念进行判定的树形流程；基于逻辑的学习的代表是归纳逻辑程序设计（Inductive Logic Programming，简称ILP）。\n",
    "\n",
    "总结：经历了推理期和知识期。推理期通过演绎推理取得了成就，代表有信息熵；知识期通过获取和利用领域知识建立专家系统取得大量成果\n",
    "\n",
    "1983：利用神经网络解决“流动性推销员”NP难问题\n",
    "1986：神经网络BP算法发明\n",
    "1963：提出支持向量概念\n",
    "1968：VC维\n",
    "1974：结构风险最小化原则\n",
    "1990：“统计学习”占据主流舞台，代表技术是支持向量机（Support Vector Machine，简称SVM）以及更一般的“核方法”（kernel methods）。文本分类中性能表现优越\n",
    "2000：深度学习的热潮，涉及语音、图像等复杂对象的应用中，深度学习技术取得了优越性能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 应用现状"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器学习应用于：多媒体、图形学、网络通信、软件工程、体系结构、芯片设计\n",
    "为计算机视觉、自然语言处理领域提供技术进步的源泉\n",
    "支持交叉学科，生物信息学、基因组计划、基因药物\n",
    "天气预报、能源勘探、环境监测\n",
    "商业营销、客户信息分析、优化库存降低成本\n",
    "搜索引擎建立输入与输出之间的联系\n",
    "自动驾驶\n",
    "美国大选"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 阅读材料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 模型评估与选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 经验误差与过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "错误率（error rate）E = 分类错误的样本数a / 样本总数m\n",
    "精度（accuracy） = 1-错误率 = 1 - a / m\n",
    "误差（error） = |预测输出 - 真实输出|\n",
    "训练误差（training error）/经验误差：训练集上的误差 = |训练集预测输出 - 训练集真实输出|\n",
    "泛化误差（generalization error）：新样本上的误差\n",
    "\n",
    "我们的目标，是泛化误差最小化，但事先并不知道新样本是什么样，实际能做的，是使得经验误差最小化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分类错误率为0，精度为100%，大多数情况，对新样本的预测效果都不好\n",
    "过拟合：模型将训练样本自身的一些特点当做了所有潜在样本都会具有的一般性质，导致泛化性能下降\n",
    "欠拟合：训练样本一般性质尚未学好\n",
    "\n",
    "过拟合通常无法避免，欠拟合可以解决"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 评估方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "留出法：数据集D互斥的划分为训练集S和测试集T（D=S∪T，S∩T=∅）\n",
    "（1）保证训练集S和测试集T的数据分布一致\n",
    "（2）多次划分训练结果求平均\n",
    "（3）测试集T不可过少，否则结果不稳定不精确，但是也不可过多，否则训练集S与数据集D误差大，常见的做法是2/3~4/5用于训练，剩下用于测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "交叉验证法：数据集D互斥的划分为K个子集，每次用K-1个集合训练，剩余子集用于测试，重复进行K次求平均\n",
    "（1）K通常取值是10，称为10折交叉验证\n",
    "（2）K划分通常也会进行多次，最终求每一次交叉验证的均值，通常为10次10折交叉验证\n",
    "（3）留一法的意思是，每个子集只有一个样本，训练集和数据集只差一个样本，非常相似，更加准确（准确度高，但计算复杂度过高，百万样本一次计算足够耗时，这里要重复计算百万-1次）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自助法：m个样本的数据集D采样m次，得到m个样本的采样数据集D'（包含重复样本）用于训练集，D中排除掉D'剩下的用于测试集\n",
    "（1）m个样本，m次始终不被采样到的概率p=(1-1/m)^m\n",
    "（2）假设样本量很大，limit(p) = 1/e = 0.368，也就是有约1/3的样本用于训练集\n",
    "（3）数据量不够的时候，使用此法更合适，数据量很大时，使用留出法或交叉验证法更合适"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调参：大多数机器学习算法都有参数需要调节\n",
    "（1）离散参数，可以把每一种都计算模型，看哪个泛化性能好\n",
    "（2）连续参数，往往通过范围+步长，选取参数值，计算模型，看哪个泛化性能好\n",
    "（3）调参后模型固定，最终对比得到的性能好的模型，因为只使用了部分样本训练，这个时候，参数固定了，还需要使用全部的数据集D进行训练，得到的模型交付给用户"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也就是说，机器学习的一般过程\n",
    "（1）根据数据集D划分训练集和测试集，最终选定学习算法和参数；\n",
    "（2）固化了学习算法和参数后，再用全数据集训练得到最终模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 性能度量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测任务中，样例集D={(x1,y1),(x2,y2),...,(xm,ym)}，y为示例x的真实标记\n",
    "模型为f(x)，评估性能就是要把对应的预测f(x)与真实的y进行比较"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回归任务的性能度量：均方误差\n",
    "离散：E(f;D)=(1/m)∑(f(xi)-yi)^2     其中，i为1~m\n",
    "连续：E(f;D)=∫(f(x)-y)^2 * p(x)dx    其中，p(x)为原始数据集D的概率密度分布，也表示xi的权重占比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "错误率（预测判别错误的占比）：\n",
    "    离散  E(f;D)=(1/m)∑BOOL(f(xi)≠yi)\n",
    "    连续  E(f;D)=∫BOOL(f(xi)≠yi)p(x)dx\n",
    "精度（预测判别正确的占比）：acc(f;D)=1-E(f;D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查准率（precision）：查准率是相对某一个指标的，比如判断瓜是好瓜的查准率，或者判断瓜是坏瓜的查准率\n",
    "   查准率P = 某个指标判别认为是正确的且该指标真实是正确的样本数 / 某个指标判别认为是正确的样本数\n",
    "查全率（recall）：查全率也是相对某一个指标的\n",
    "   查全率R = 某个指标判别认为是正确的样本数 / 某个指标真实是正确的样本数\n",
    "   \n",
    "查准率是用来衡量判别的准确率的，这个意义比较大，是衡量模型的关键指标，衡量模型准确率的\n",
    "查全率是用来衡量全样本中被成功判别出来的比例，也就是说还有多少是漏报的，衡量分类完整性的\n",
    "\n",
    "查准率和查全率组成的曲线，称为P-R曲线（横坐标是查全率R，纵坐标是查准率P）。平衡点（BEP）为斜率为1的直线与P-R曲线的交点，平衡点越靠外，性能越好\n",
    "\n",
    "查准率和查全率是相互矛盾的指标，实际项目过程中，往往根据情况选择偏向重视程度，不一定是根据平衡点来决策"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC和AUC同P-R曲线类似，实际使用中再仔细查看"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代价敏感错误率：正确判别为错误，或者错误判别为正确。应使这个错误率偏小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 比较检验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设检验：泛化错误率 ≤ e0 的假设，检验这个假设是否靠谱。e0是我们估计的一个值，实际是检验这个估计靠不靠谱。\n",
    "假设检验方法：\n",
    "（1）假设检验假设靠谱的情况下，求出置信区间。求置信区间方法是，取a=95%或者1%或者0.1%作为可信程度，只要处于置信区间中概率总和大于a，则认为可信，由置信区间得到置信边界条件。\n",
    "（2）另外由观测值可以求出一个e'\n",
    "（3）要确保e'在置信区间内，否则在置信区间外，认为小概率事件发生了，那么假设就不应该成立"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 偏差与方差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 阅读材料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 线性模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 支持向量机"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 贝叶斯分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 集成学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 聚类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 降维与度量学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 特征选择与稀疏学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 计算学习理论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13 半监督学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14 概率图模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15 规则学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16 强化学习"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
